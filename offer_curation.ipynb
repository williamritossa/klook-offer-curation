{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b14c7c",
   "metadata": {},
   "source": [
    "# Klook Offer Curation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb686d",
   "metadata": {},
   "source": [
    "This notebook loads raw Klook offers, structures the relevant content, and uses the OpenAI Responses API to produce curation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, List\n",
    "\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from IPython.display import display\n",
    "\n",
    "# Ensure DataFrame columns like 'reason' show full content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd73e268",
   "metadata": {},
   "source": [
    "## Data Import and Structuring\n",
    "Helpers for loading raw offer JSON files and shaping them into the consistent structure used downstream (`load_offers`, `extract_images`, `render_sections`, `structure_activity`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae922b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFERS_DIR = Path(\"offers\")\n",
    "\n",
    "\n",
    "def load_offers(directory: Path) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load all JSON offers in the given directory.\"\"\"\n",
    "    offers: List[Dict[str, Any]] = []\n",
    "    for path in sorted(directory.glob(\"*.json\")):\n",
    "        with path.open(\"r\", encoding=\"utf-8\") as fh:\n",
    "            payload = json.load(fh)\n",
    "        activity = payload.get(\"activity\")\n",
    "        if activity:\n",
    "            offers.append({\"path\": str(path), \"activity\": activity})\n",
    "    return offers\n",
    "\n",
    "\n",
    "def extract_images(images: Iterable[Dict[str, Any]] | None) -> List[str]:\n",
    "    \"\"\"Flatten the image list into absolute URLs.\"\"\"\n",
    "    urls: List[str] = []\n",
    "    if not images:\n",
    "        return urls\n",
    "    for image in images:\n",
    "        if not isinstance(image, dict):\n",
    "            continue\n",
    "        host_url = image.get(\"image_url_host\")\n",
    "        if host_url:\n",
    "            urls.append(host_url)\n",
    "        nested = image.get(\"images\")\n",
    "        if isinstance(nested, list):\n",
    "            for nested_image in nested:\n",
    "                if isinstance(nested_image, dict):\n",
    "                    nested_url = nested_image.get(\"image_url_host\")\n",
    "                    if nested_url:\n",
    "                        urls.append(nested_url)\n",
    "    # Preserve order while removing duplicates\n",
    "    seen = set()\n",
    "    unique_urls = []\n",
    "    for url in urls:\n",
    "        if url not in seen:\n",
    "            unique_urls.append(url)\n",
    "            seen.add(url)\n",
    "    return unique_urls\n",
    "\n",
    "\n",
    "def render_sections(section_info: Iterable[Dict[str, Any]] | None) -> str:\n",
    "    \"\"\"Convert section metadata into markdown text.\"\"\"\n",
    "    if not section_info:\n",
    "        return \"\"\n",
    "    chunks: List[str] = []\n",
    "    for section in section_info:\n",
    "        if not isinstance(section, dict):\n",
    "            continue\n",
    "        section_name = (section.get(\"section_name\") or \"\").strip()\n",
    "        group_blocks: List[str] = []\n",
    "        for group in section.get(\"groups\", []):\n",
    "            if not isinstance(group, dict):\n",
    "                continue\n",
    "            group_name = (group.get(\"group_name\") or \"\").strip()\n",
    "            content = (group.get(\"content\") or \"\").strip()\n",
    "            if group_name and content:\n",
    "                group_blocks.append(f\"### {group_name}\\n{content}\")\n",
    "            elif content:\n",
    "                group_blocks.append(content)\n",
    "        body = \"\\n\\n\".join([block for block in group_blocks if block])\n",
    "        if section_name and body:\n",
    "            chunks.append(f\"## {section_name}\\n{body}\")\n",
    "        elif body:\n",
    "            chunks.append(body)\n",
    "    return \"\\n\\n\".join([chunk for chunk in chunks if chunk])\n",
    "\n",
    "\n",
    "def structure_activity(activity: Dict[str, Any], source_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"Extract the fields needed for grading from an activity payload.\"\"\"\n",
    "    packages: List[Dict[str, Any]] = []\n",
    "    for package in activity.get(\"package_list\", []) or []:\n",
    "        if not isinstance(package, dict):\n",
    "            continue\n",
    "        packages.append({\n",
    "            \"package_id\": package.get(\"package_id\"),\n",
    "            \"package_name\": package.get(\"package_name\"),\n",
    "            \"sections_markdown\": render_sections(package.get(\"section_info\")),\n",
    "        })\n",
    "    city_info = activity.get(\"city_info\") or []\n",
    "    primary_city = city_info[0] if city_info else {}\n",
    "    category_info = activity.get(\"category_info\") or {}\n",
    "    status = activity.get(\"status\") or activity.get(\"curation_status\") or category_info.get(\"curation_status\")\n",
    "\n",
    "    return {\n",
    "        \"source_path\": source_path,\n",
    "        \"activity_id\": activity.get(\"activity_id\"),\n",
    "        \"title\": activity.get(\"title\"),\n",
    "        \"subtitle\": activity.get(\"subtitle\"),\n",
    "        \"what_we_love\": activity.get(\"what_we_love\"),\n",
    "        \"location\": activity.get(\"location\"),\n",
    "        \"address\": activity.get(\"address_desc_multilang\"),\n",
    "        \"category\": category_info.get(\"sub_category_name\"),\n",
    "        \"category_detail\": category_info,\n",
    "        \"description_markdown\": render_sections(activity.get(\"section_info\")),\n",
    "        \"packages\": packages,\n",
    "        \"images\": extract_images(activity.get(\"images\")),\n",
    "        \"city\": primary_city.get(\"city_name\"),\n",
    "        \"country\": primary_city.get(\"country_name\"),\n",
    "        \"status\": status,\n",
    "        \"raw\": activity,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797215c1",
   "metadata": {},
   "source": [
    "## Curation via GPT\n",
    "Utilities that prepare prompts, call the OpenAI Responses API, and interpret grading results (`load_api_key_from_file`, `load_api_key`, `get_client`, `summarise_packages`, `build_offer_prompt`, `collect_response_text`, `parse_json_response`, `grade_offer`, `grade_offers_parallel`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e57104",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a senior Luxury Escapes curation editor. Evaluate each Klook offer for suitability on our platform.\n",
    "Consider title clarity, image relevance, category accuracy, description quality, and location correctness.\n",
    "Return a strict JSON object with keys:\n",
    "- score (0-5, integer)\n",
    "- categories (array of categories that best describe the Klook activity. You can only choose from the list below)\n",
    "- target_audiences (array of target audiences that best describe the Klook activity. You can only choose from the list below)\n",
    "- reason (concise justification including any category recommendations or red flags).\n",
    "\n",
    "## Categories\n",
    "These are the possible categories, note each is nested in a parent category. Do not include the parent category in the array.\n",
    "\n",
    "{\n",
    "  \"Wine & Dine\": [\n",
    "    \"Fine dining\",\n",
    "    \"Restaurants & bars\",\n",
    "    \"Caf√©s\",\n",
    "    \"High tea\",\n",
    "    \"Food tours\",\n",
    "    \"Wine country trips\",\n",
    "    \"Breweries, distilleries & vineyards\"\n",
    "  ],\n",
    "  \"Top Activities\": [\n",
    "    \"Yachts, boats & cruises\",\n",
    "    \"Cooking classes\",\n",
    "    \"Up in the air\",\n",
    "    \"Outdoor activities\",\n",
    "    \"Watersports\",\n",
    "    \"Indoor activities\",\n",
    "    \"Photoshoot - Travelshoot\",\n",
    "    \"Wildlife Cruises\",\n",
    "    \"Cinemas\",\n",
    "    \"Golf\",\n",
    "    \"Ski\",\n",
    "    \"Beach & Pool Clubs\",\n",
    "    \"School Holidays\"\n",
    "  ],\n",
    "  \"Attractions & Tickets\": [\n",
    "    \"Theme & water parks\",\n",
    "    \"Attraction passes\",\n",
    "    \"Museums\",\n",
    "    \"Zoos & aquariums\",\n",
    "    \"Historical sites\",\n",
    "    \"Galleries\"\n",
    "  ],\n",
    "  \"Live Events\": [\n",
    "    \"Concerts\",\n",
    "    \"Theatre\",\n",
    "    \"Live sports\",\n",
    "    \"Special Events\"\n",
    "  ],\n",
    "  \"Indulge Yourself\": [\n",
    "    \"Spa & massage\",\n",
    "    \"Hot springs\",\n",
    "    \"Wellness\"\n",
    "  ],\n",
    "  \"Lux Exclusives\": [\n",
    "    \"The best of the best\"\n",
    "  ],\n",
    "  \"Travel Essentials\": [\n",
    "    \"Airport lounges\",\n",
    "    \"Luggage\",\n",
    "    \"Airport Services\",\n",
    "    \"Water Transfers\"\n",
    "  ],\n",
    "  \"Day Tours\": [\n",
    "    \"Guided tours\",\n",
    "    \"Walking tours\",\n",
    "    \"Bike tours\",\n",
    "    \"Hop-on-hop-off\",\n",
    "    \"Private tours\"\n",
    "  ],\n",
    "  \"Gift Inspiration\": [\n",
    "    \"Foodie\",\n",
    "    \"Thrill Seeker\",\n",
    "    \"Animal Lover\",\n",
    "    \"Spa-goer\",\n",
    "    \"Family\",\n",
    "    \"Aquatic Enthusiast\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "## Target Audiences\n",
    "These are the possible target audiences. Some or all can apply (it is most common for all to apply).\n",
    "- Solo\n",
    "- Couple\n",
    "- Group\n",
    "- Family\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dbc892",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_IMAGES_TO_REVIEW = 8\n",
    "MODEL_NAME = \"gpt-5\"\n",
    "REASONING_EFFORT = \"medium\"\n",
    "MAX_OUTPUT_TOKENS = 5000\n",
    "OPENAI_API_KEY_ENV = \"OPENAI_API_KEY\"\n",
    "ENV_PRIORITIES = [\n",
    "    Path(\".env\"),\n",
    "    Path(\".openai_api_key\"),\n",
    "]\n",
    "\n",
    "def load_api_key_from_file(path: Path) -> str | None:\n",
    "    try:\n",
    "        content = path.read_text(encoding=\"utf-8\")\n",
    "    except OSError:\n",
    "        return None\n",
    "    for raw_line in content.splitlines():\n",
    "        line = raw_line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        if \"=\" not in line:\n",
    "            continue\n",
    "        key, value = line.split(\"=\", 1)\n",
    "        if key.strip() == OPENAI_API_KEY_ENV:\n",
    "            return value.strip().strip('\"')\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_api_key() -> str | None:\n",
    "    value = os.getenv(OPENAI_API_KEY_ENV)\n",
    "    if value:\n",
    "        return value.strip()\n",
    "    for env_path in ENV_PRIORITIES:\n",
    "        if env_path.exists():\n",
    "            candidate = load_api_key_from_file(env_path)\n",
    "            if candidate:\n",
    "                return candidate\n",
    "    return None\n",
    "\n",
    "\n",
    "_client: OpenAI | None = None\n",
    "\n",
    "\n",
    "def get_client() -> OpenAI:\n",
    "    \"\"\"Return a shared OpenAI client, raising if the API key is missing.\"\"\"\n",
    "    global _client\n",
    "    if _client is None:\n",
    "        api_key = load_api_key()\n",
    "        if not api_key:\n",
    "            raise RuntimeError(\n",
    "                \"OpenAI API key not found. Set OPENAI_API_KEY or add it to a local .env file.\"\n",
    "            )\n",
    "        _client = OpenAI(api_key=api_key)\n",
    "    return _client\n",
    "\n",
    "\n",
    "def summarise_packages(packages: List[Dict[str, Any]]) -> str:\n",
    "    if not packages:\n",
    "        return \"No packages available.\"\n",
    "    lines: List[str] = []\n",
    "    for idx, package in enumerate(packages, start=1):\n",
    "        name = package.get(\"package_name\") or f\"Package {idx}\"\n",
    "        details = package.get(\"sections_markdown\") or \"No details supplied.\"\n",
    "        lines.append(f\"Package: {name}\\n{details}\")\n",
    "    return \"\\n\\n\".join(lines)\n",
    "\n",
    "\n",
    "def build_offer_prompt(offer: Dict[str, Any]) -> str:\n",
    "    \"\"\"Format the offer payload into a single prompt string.\"\"\"\n",
    "    lines = [\n",
    "        f\"Activity ID: {offer.get('activity_id')}\",\n",
    "        f\"Title: {offer.get('title') or 'N/A'}\",\n",
    "        f\"Subtitle: {offer.get('subtitle') or 'N/A'}\",\n",
    "        f\"What we love: {offer.get('what_we_love') or 'N/A'}\",\n",
    "        f\"Location (lat,long): {offer.get('location') or 'N/A'}\",\n",
    "        f\"Address: {offer.get('address') or 'N/A'}\",\n",
    "        f\"City: {offer.get('city') or 'N/A'}\",\n",
    "        f\"Country: {offer.get('country') or 'N/A'}\",\n",
    "        f\"Current category: {offer.get('category') or 'N/A'}\",\n",
    "        \"\",\n",
    "        \"Offer description markdown:\",\n",
    "        offer.get('description_markdown') or 'No description supplied.',\n",
    "        \"\",\n",
    "        \"Packages:\",\n",
    "        summarise_packages(offer.get('packages') or []),\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def collect_response_text(response: Any) -> str:\n",
    "    \"\"\"Extract concatenated text from a Responses API call.\"\"\"\n",
    "    payload = response.to_dict() if hasattr(response, \"to_dict\") else response\n",
    "    chunks: list[str] = []\n",
    "    for item in payload.get(\"output\", []):\n",
    "        for content in item.get(\"content\", []):\n",
    "            if content.get(\"type\") == \"output_text\":\n",
    "                chunks.append(content.get(\"text\", \"\"))\n",
    "    return \"\".join(chunks).strip()\n",
    "\n",
    "\n",
    "def parse_json_response(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"Parse the model's JSON response, tolerating surrounding text.\"\"\"\n",
    "    if not text:\n",
    "        return {\"score\": None, \"reason\": \"Empty response from model.\"}\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        import re\n",
    "        match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return json.loads(match.group(0))\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "    return {\"score\": None, \"reason\": f\"Failed to parse JSON: {text}\"}\n",
    "\n",
    "\n",
    "\n",
    "def normalise_str_list(value: Any) -> List[str]:\n",
    "    \"\"\"Return a list of strings for JSON list-or-string values.\"\"\"\n",
    "    if isinstance(value, list):\n",
    "        return [str(item) for item in value if item is not None]\n",
    "    if value in (None, \"\"):\n",
    "        return []\n",
    "    return [str(value)]\n",
    "\n",
    "def grade_offer(offer: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Call the OpenAI Responses API to grade a single offer.\"\"\"\n",
    "    client = get_client()\n",
    "    prompt = build_offer_prompt(offer)\n",
    "\n",
    "    image_payload = [\n",
    "        {\"type\": \"input_image\", \"image_url\": url}\n",
    "        for url in (offer.get(\"images\") or [])[:MAX_IMAGES_TO_REVIEW]\n",
    "    ]\n",
    "\n",
    "    offer_content = [{\"type\": \"input_text\", \"text\": prompt}] + image_payload\n",
    "    response_id: str | None = None\n",
    "    categories: List[str] = []\n",
    "    target_audiences: List[str] = []\n",
    "\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=MODEL_NAME,\n",
    "            instructions=SYSTEM_PROMPT,\n",
    "            input=[{\"role\": \"user\", \"content\": offer_content}],\n",
    "            reasoning={\"effort\": REASONING_EFFORT},\n",
    "            max_output_tokens=MAX_OUTPUT_TOKENS,\n",
    "            metadata={\n",
    "                \"activity_id\": str(offer.get(\"activity_id\")),\n",
    "                \"activity_title\": offer.get(\"title\"),\n",
    "                \"activity_url\": f\"https://www.klook.com/en-AU/activity/{offer.get('activity_id')}\",\n",
    "                \"activity_category\": offer.get(\"category\"),\n",
    "            },\n",
    "        )\n",
    "        response_id = getattr(response, \"id\", None)\n",
    "        response_text = collect_response_text(response)\n",
    "        parsed = parse_json_response(response_text)\n",
    "        categories = normalise_str_list(parsed.get(\"categories\"))\n",
    "        target_audiences = normalise_str_list(parsed.get(\"target_audiences\"))\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        detail = getattr(exc, \"response\", None)\n",
    "        extra_info = None\n",
    "        if detail is not None:\n",
    "            try:\n",
    "                extra_info = detail.json()\n",
    "            except Exception:  # noqa: BLE001\n",
    "                if hasattr(detail, \"text\") and detail.text:\n",
    "                    extra_info = detail.text\n",
    "                elif hasattr(detail, \"content\") and detail.content:\n",
    "                    extra_info = detail.content\n",
    "        reason = f\"Model call failed: {exc}\"\n",
    "        if extra_info is not None:\n",
    "            reason = f\"{reason} | {extra_info}\"\n",
    "        return {\n",
    "            \"activity_id\": offer.get(\"activity_id\"),\n",
    "            \"score\": None,\n",
    "            \"reason\": reason,\n",
    "            \"categories\": categories,\n",
    "            \"target_audiences\": target_audiences,\n",
    "            \"response_id\": None,\n",
    "        }\n",
    "\n",
    "    score = parsed.get(\"score\")\n",
    "    try:\n",
    "        score_value = float(score) if score is not None else None\n",
    "    except (TypeError, ValueError):\n",
    "        score_value = None\n",
    "    if score_value is not None:\n",
    "        score_value = max(0.0, min(5.0, score_value))\n",
    "\n",
    "    reason = parsed.get(\"reason\") or parsed\n",
    "    if isinstance(reason, dict):\n",
    "        reason = json.dumps(reason)\n",
    "\n",
    "    return {\n",
    "        \"activity_id\": offer.get(\"activity_id\"),\n",
    "        \"score\": score_value,\n",
    "        \"reason\": reason,\n",
    "        \"categories\": categories,\n",
    "        \"target_audiences\": target_audiences,\n",
    "        \"response_id\": response_id,\n",
    "    }\n",
    "\n",
    "\n",
    "def grade_offers_parallel(offers: List[Dict[str, Any]], max_workers: int | None = None) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Grade offers in parallel using a thread pool.\"\"\"\n",
    "    if not offers:\n",
    "        return []\n",
    "    worker_count = max_workers or min(8, len(offers)) or 1\n",
    "    results: List[Dict[str, Any]] = []\n",
    "    with ThreadPoolExecutor(max_workers=worker_count) as executor:\n",
    "        future_map = {executor.submit(grade_offer, offer): offer for offer in offers}\n",
    "        for future in as_completed(future_map):\n",
    "            offer = future_map[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "            except Exception as exc:  # noqa: BLE001\n",
    "                result = {\n",
    "                    \"activity_id\": offer.get(\"activity_id\"),\n",
    "                    \"score\": None,\n",
    "                    \"reason\": f\"Unexpected error: {exc}\",\n",
    "                    \"categories\": [],\n",
    "                    \"target_audiences\": [],\n",
    "                    \"response_id\": None,\n",
    "                }\n",
    "            results.append(result)\n",
    "    results.sort(key=lambda item: (item.get(\"activity_id\"), item.get(\"reason\")))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec7665",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_offers = load_offers(OFFERS_DIR)\n",
    "structured_offers = [structure_activity(item[\"activity\"], item[\"path\"]) for item in raw_offers]\n",
    "print(f\"Loaded {len(structured_offers)} offers from {OFFERS_DIR.resolve()}\")\n",
    "overview_records = [\n",
    "    {\n",
    "        \"activity_id\": offer.get(\"activity_id\"),\n",
    "        \"title\": offer.get(\"title\"),\n",
    "        \"city\": offer.get(\"city\"),\n",
    "        \"country\": offer.get(\"country\"),\n",
    "        \"category\": offer.get(\"category\"),\n",
    "        \"status\": offer.get(\"status\"),\n",
    "        \"image_count\": len(offer.get(\"images\") or []),\n",
    "        \"package_count\": len(offer.get(\"packages\") or []),\n",
    "    }\n",
    "    for offer in structured_offers\n",
    "]\n",
    "overview_df = pd.DataFrame(overview_records)\n",
    "overview_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if structured_offers:\n",
    "    sample_offer = structured_offers[0]\n",
    "    sample_summary = {\n",
    "        \"activity_id\": sample_offer.get(\"activity_id\"),\n",
    "        \"title\": sample_offer.get(\"title\"),\n",
    "        \"subtitle\": sample_offer.get(\"subtitle\"),\n",
    "        \"what_we_love\": sample_offer.get(\"what_we_love\"),\n",
    "        \"location\": sample_offer.get(\"location\"),\n",
    "        \"category\": sample_offer.get(\"category\"),\n",
    "        \"images\": sample_offer.get(\"images\"),\n",
    "        \"description_markdown\": sample_offer.get(\"description_markdown\"),\n",
    "    }\n",
    "    pd.Series(sample_summary)\n",
    "else:\n",
    "    print(\"No offers found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a5325",
   "metadata": {},
   "outputs": [],
   "source": [
    "if structured_offers:\n",
    "    sample_packages = pd.DataFrame(structured_offers[0].get(\"packages\") or [])\n",
    "    sample_packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7c14e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_to_grade = [\n",
    "    offer for offer in structured_offers\n",
    "    if (offer.get(\"status\") or \"\").upper() != \"CURATED\"\n",
    "]\n",
    "print(f\"Queued {len(offers_to_grade)} offers for grading.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea8e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if offers_to_grade:\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"OPENAI_API_KEY is not set in this kernel session. Skipping grading.\")\n",
    "    else:\n",
    "        grading_results = grade_offers_parallel(offers_to_grade)\n",
    "        results_df = pd.DataFrame(grading_results)\n",
    "        results_df[\"activity_url\"] = results_df[\"activity_id\"].apply(\n",
    "            lambda x: f\"https://www.klook.com/en-AU/activity/{x}\" if pd.notna(x) else None\n",
    "        )\n",
    "        results_df[\"log_url\"] = results_df[\"response_id\"].apply(\n",
    "            lambda resp: f\"https://platform.openai.com/logs/{resp}\"\n",
    "            if isinstance(resp, str) and resp\n",
    "            else None\n",
    "        )\n",
    "        results_df = results_df[[\"activity_id\", \"activity_url\", \"categories\", \"target_audiences\", \"score\", \"reason\", \"log_url\"]]\n",
    "        display(results_df)\n",
    "else:\n",
    "    print(\"No offers require grading.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af184d",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51970fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'results_df' in locals():\n",
    "    export_path = Path('graded_offers.csv')\n",
    "    results_df.to_csv(export_path, index=False)\n",
    "    print(f'Exported results to {export_path.resolve()}')\n",
    "else:\n",
    "    print('results_df is not defined. Run the grading cell first.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
